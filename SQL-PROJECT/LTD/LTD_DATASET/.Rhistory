method = "cv",
number = 10,
classProbs = TRUE,
summaryFunction = twoClassSummary,
savePredictions = "final"
)
# STEP 7: SVM KERNEL GRID DEFINITIONS
grid_radial <- expand.grid(C = 2^(-1:4), sigma = 2^(-5:1))
grid_poly   <- expand.grid(degree = 2:3, scale = c(0.01, 0.1), C = 2^(0:4))
# STEP 8: TRAIN SVM MODELS
svm_radial <- train(Class ~ .,
data = train_data,
method = "svmRadial",
metric = "ROC",
preProcess = c("center", "scale"),
tuneGrid = grid_radial,
trControl = trControl)
Final safety checks
# === Load required packages ===
install.packages("caret", dependencies = TRUE)
install.packages("e1071")
library(caret)
library(e1071)
# === Load the dataset ===
data("GermanCredit")
# === Set seed and split into training/testing sets ===
set.seed(123)
index <- createDataPartition(GermanCredit$Class, p = 0.8, list = FALSE)
train_data <- GermanCredit[index, ]
test_data <- GermanCredit[-index, ]
# === Train SVM with RBF kernel ===
svm_model <- svm(Class ~ .,
data = train_data,
kernel = "radial",
cost = 1,
gamma = 0.01)
# === Predict on test set ===
predictions <- predict(svm_model, newdata = test_data)
# === Evaluate model performance ===
confusion <- confusionMatrix(predictions, test_data$Class)
print(confusion)
# === Optional: Hyperparameter tuning ===
tuned <- tune(svm, Class ~ .,
data = train_data,
kernel = "radial",
ranges = list(cost = c(0.1, 1, 10), gamma = c(0.01, 0.05, 0.1)))
# === Print tuning results ===
print(tuned)
best_model <- tuned$best.model
# === Evaluate tuned model ===
best_predictions <- predict(best_model, newdata = test_data)
best_confusion <- confusionMatrix(best_predictions, test_data$Class)
print(best_confusion)
# === Install and Load Required Packages ===
install.packages("caret", dependencies = TRUE)
install.packages("e1071")
install.packages("pROC")
install.packages("ggplot2")
install.packages("reshape2")
library(caret)
library(e1071)
library(pROC)
library(ggplot2)
library(reshape2)
# === Load the dataset ===
data("GermanCredit")
# === Set seed and split into training/testing sets ===
set.seed(123)
index <- createDataPartition(GermanCredit$Class, p = 0.8, list = FALSE)
train_data <- GermanCredit[index, ]
test_data <- GermanCredit[-index, ]
# === Train SVM with RBF kernel ===
svm_model <- svm(Class ~ .,
data = train_data,
kernel = "radial",
cost = 1,
gamma = 0.01)
# === Predict on test set ===
predictions <- predict(svm_model, newdata = test_data)
pred_prob <- predict(svm_model, newdata = test_data, decision.values = TRUE)
# === Confusion Matrix ===
confusion <- confusionMatrix(predictions, test_data$Class)
print(confusion)
# === Confusion Matrix Heatmap ===
conf_matrix <- confusionMatrix(predictions, test_data$Class)
conf_matrix_data <- as.data.frame(conf_matrix$table)
names(conf_matrix_data) <- c("Predicted", "Actual", "Freq")
ggplot(data = conf_matrix_data, aes(x = Actual, y = Predicted, fill = Freq)) +
geom_tile() +
scale_fill_gradient(low = "white", high = "blue") +
theme_minimal() +
labs(title = "Confusion Matrix Heatmap", x = "Actual", y = "Predicted") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# === Precision, Recall, F1-Score ===
precision <- posPredValue(predictions, test_data$Class, positive = "Good")
recall <- sensitivity(predictions, test_data$Class, positive = "Good")
f1_score <- (2 * precision * recall) / (precision + recall)
cat("Precision: ", precision, "\n")
cat("Recall: ", recall, "\n")
cat("F1-Score: ", f1_score, "\n")
#SVM-STEP 4: CONFUSION MATRIX + PERFORMANCE METRICS
conf_matrix <- confusionMatrix(predictions, test_data$Class)
# === Install and Load Required Packages ===
install.packages("caret", dependencies = TRUE)
install.packages("e1071")
install.packages("pROC")
install.packages("ggplot2")
install.packages("reshape2")
library(caret)
library(e1071)
library(pROC)
library(ggplot2)
library(reshape2)
# === Load the dataset ===
data("GermanCredit")
# === Set seed and split into training/testing sets ===
set.seed(123)
index <- createDataPartition(GermanCredit$Class, p = 0.8, list = FALSE)
# === Set seed and split into training/testing sets ===
set.seed(123)
index <- createDataPartition(GermanCredit$Class, p = 0.8, list = FALSE)
# === Install and Load Required Packages ===
install.packages("caret", dependencies = TRUE)
install.packages("e1071")
install.packages("pROC")
install.packages("ggplot2")
install.packages("reshape2")
library(caret)
library(e1071)
library(pROC)
library(ggplot2)
library(reshape2)
# === Load the dataset ===
data("GermanCredit")
# === Set seed and split into training/testing sets ===
set.seed(123)
index <- createDataPartition(GermanCredit$Class, p = 0.8, list = FALSE)
train_data <- GermanCredit[index, ]
test_data <- GermanCredit[-index, ]
# === Train SVM with RBF kernel ===
svm_model <- svm(Class ~ .,
data = train_data,
kernel = "radial",
cost = 1,
gamma = 0.01)
# === Predict on test set ===
predictions <- predict(svm_model, newdata = test_data)
pred_prob <- predict(svm_model, newdata = test_data, decision.values = TRUE)
# === Confusion Matrix ===
confusion <- confusionMatrix(predictions, test_data$Class)
print(confusion)
# === Confusion Matrix Heatmap ===
conf_matrix <- confusionMatrix(predictions, test_data$Class)
conf_matrix_data <- as.data.frame(conf_matrix$table)
names(conf_matrix_data) <- c("Predicted", "Actual", "Freq")
ggplot(data = conf_matrix_data, aes(x = Actual, y = Predicted, fill = Freq)) +
geom_tile() +
scale_fill_gradient(low = "white", high = "blue") +
theme_minimal() +
labs(title = "Confusion Matrix Heatmap", x = "Actual", y = "Predicted") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# === Precision, Recall, F1-Score ===
precision <- posPredValue(predictions, test_data$Class, positive = "Good")
recall <- sensitivity(predictions, test_data$Class, positive = "Good")
f1_score <- (2 * precision * recall) / (precision + recall)
cat("Precision: ", precision, "\n")
cat("Recall: ", recall, "\n")
cat("F1-Score: ", f1_score, "\n")
# === ROC Curve and AUC ===
roc_curve <- roc(test_data$Class, as.numeric(pred_prob[, 2]), levels = rev(levels(test_data$Class)))
# STEP 1: LOAD LIBRARIES
install.packages("e1071")
install.packages("caTools")
install.packages("caret")
install.packages("mlbench")
# === Train SVM with RBF kernel ===
svm_model <- svm(Class ~ .,
data = train_data,
kernel = "radial",
cost = 1,
gamma = 0.01)
# STEP 1: LOAD LIBRARIES
install.packages("e1071")
install.packages("caTools")
install.packages("caret")
install.packages("mlbench")
install.packages("ggplot2")
install.packages("pROC")
library(mlbench)
library(caret)
library(e1071)
library(caTools)
library(ggplot2)
library(pROC)
# STEP 2: LOAD, VIEW, AND PREPARE DATA SET
# Load the dataset
data("GermanCredit")
head(GermanCredit)
str(GermanCredit)
# Convert categorical variables to factors
GermanCredit[sapply(GermanCredit, is.character)] <- lapply(GermanCredit[sapply(GermanCredit, is.character)], factor)
# STEP 3: TRAIN AND TEST DATASET
# Split the dataset into training (70%) and test sets (30%)
set.seed(123)  # Set seed for reproducibility
split <- sample.split(GermanCredit$Class, SplitRatio = 0.7)
train_data <- subset(GermanCredit, split == TRUE)
test_data <- subset(GermanCredit, split == FALSE)
# === Train SVM with RBF kernel ===
svm_model <- svm(Class ~ .,
data = train_data,
kernel = "radial",
cost = 1,
gamma = 0.01)
# === Predict on test set ===
predictions <- predict(svm_model, newdata = test_data)
pred_prob <- predict(svm_model, newdata = test_data, decision.values = TRUE)
# === Confusion Matrix ===
conf_matrix <- confusionMatrix(predictions, test_data$Class)
# Print confusion matrix
print(conf_matrix)
# Extract precision, recall, and F1-score
precision <- conf_matrix$byClass["Precision"]
recall <- conf_matrix$byClass["Recall"]
f1_score <- 2 * (precision * recall) / (precision + recall)
# Print performance metrics
print(paste("Precision: ", round(precision, 3)))
print(paste("Recall: ", round(recall, 3)))
print(paste("F1 Score: ", round(f1_score, 3)))
# STEP 1: LOAD LIBRARIES
install.packages("e1071")
install.packages("caTools")
install.packages("caret")
install.packages("mlbench")
install.packages("ggplot2")
install.packages("pROC")
library(mlbench)
library(caret)
library(e1071)
library(caTools)
library(ggplot2)
library(pROC)
# STEP 1: LOAD LIBRARIES
install.packages("e1071")
install.packages("caTools")
install.packages("caret")
install.packages("mlbench")
install.packages("ggplot2")
install.packages("pROC")
library(mlbench)
library(caret)
library(e1071)
library(caTools)
library(ggplot2)
library(pROC)
# STEP 2: LOAD, VIEW, AND PREPARE DATA SET
# STEP 2: REMOVE CONSTANT VARIABLES
constant_vars <- sapply(GermanCredit, function(x) length(unique(x)) == 1)
# STEP 1: LOAD LIBRARIES
install.packages("e1071")
install.packages("caTools")
install.packages("caret")
install.packages("mlbench")
install.packages("ggplot2")
install.packages("pROC")
library(mlbench)
library(caret)
library(e1071)
library(caTools)
library(ggplot2)
library(pROC)
# STEP 2: LOAD, VIEW, AND PREPARE DATA SET
# === Load the dataset ===
data("GermanCredit")
# === Set seed and split into training/testing sets ===
set.seed(123)
index <- createDataPartition(GermanCredit$Class, p = 0.8, list = FALSE)
# STEP 2: REMOVE CONSTANT VARIABLES
constant_vars_train <- sapply(train_data, function(x) length(unique(x)) == 1)
# === Set seed for reproducibility ===
set.seed(123)
# === Split the dataset into training (70%) and test (30%) sets ===
index <- createDataPartition(GermanCredit$Class, p = 0.7, list = FALSE)
# STEP 1: LOAD LIBRARIES
install.packages("e1071")
install.packages("caTools")
install.packages("caret")
install.packages("mlbench")
install.packages("ggplot2")
install.packages("pROC")
library(mlbench)
library(caret)
library(e1071)
library(caTools)
library(ggplot2)
library(pROC)
# STEP 2: LOAD, VIEW, AND PREPARE DATA SET
# === Load the dataset ===
data("GermanCredit")
# === Set seed for reproducibility ===
set.seed(123)
# === Split the dataset into training (70%) and test (30%) sets ===
index <- createDataPartition(GermanCredit$Class, p = 0.7, list = FALSE)
train_data <- GermanCredit[index, ]
test_data <- GermanCredit[-index, ]
# STEP 2: REMOVE CONSTANT VARIABLES (For both training and test data)
constant_vars_train <- sapply(train_data, function(x) length(unique(x)) == 1)
train_data <- train_data[, !constant_vars_train]
constant_vars_test <- sapply(test_data, function(x) length(unique(x)) == 1)
test_data <- test_data[, !constant_vars_test]
# === Convert categorical variables to factors ===
train_data[sapply(train_data, is.character)] <- lapply(train_data[sapply(train_data, is.character)], factor)
test_data[sapply(test_data, is.character)] <- lapply(test_data[sapply(test_data, is.character)], factor)
# === Ensure target variable ('Class') is a factor ===
train_data$Class <- as.factor(train_data$Class)
test_data$Class <- as.factor(test_data$Class)
# STEP 2: SCALING THE DATA (AFTER SPLIT)
# === Scale numeric variables in the training set ===
numeric_vars_train <- sapply(train_data, is.numeric)
train_data[numeric_vars_train] <- scale(train_data[numeric_vars_train])
# === Scale numeric variables in the test set using training set scaling parameters ===
numeric_vars_test <- sapply(test_data, is.numeric)
test_data[numeric_vars_test] <- scale(test_data[numeric_vars_test],
center = attr(train_data[, numeric_vars_train], "scaled:center"),
scale = attr(train_data[, numeric_vars_train], "scaled:scale"))
# STEP 1: LOAD LIBRARIES
install.packages("e1071")
install.packages("caTools")
install.packages("caret")
install.packages("mlbench")
install.packages("ggplot2")
install.packages("pROC")
library(mlbench)
library(caret)
library(e1071)
library(caTools)
library(ggplot2)
library(pROC)
# STEP 1: LOAD LIBRARIES
install.packages("e1071")
install.packages("caTools")
install.packages("caret")
install.packages("mlbench")
install.packages("ggplot2")
install.packages("pROC")
library(mlbench)
library(caret)
library(e1071)
library(caTools)
library(ggplot2)
library(pROC)
# STEP 2: LOAD, VIEW, AND PREPARE DATA SET
# === Load the dataset ===
data("GermanCredit")
# === Set seed for reproducibility ===
set.seed(123)
# === Split the dataset into training (80%) and test (20%) sets ===
index <- createDataPartition(GermanCredit$Class, p = 0.8, list = FALSE)
train_data <- GermanCredit[index, ]
test_data <- GermanCredit[-index, ]
# STEP 2: REMOVE CONSTANT VARIABLES (For both training and test data)
constant_vars_train <- sapply(train_data, function(x) length(unique(x)) == 1)
train_data <- train_data[, !constant_vars_train]
constant_vars_test <- sapply(test_data, function(x) length(unique(x)) == 1)
test_data <- test_data[, !constant_vars_test]
# === Convert categorical variables to factors ===
train_data[sapply(train_data, is.character)] <- lapply(train_data[sapply(train_data, is.character)], factor)
test_data[sapply(test_data, is.character)] <- lapply(test_data[sapply(test_data, is.character)], factor)
# === Ensure target variable ('Class') is a factor ===
train_data$Class <- as.factor(train_data$Class)
test_data$Class <- as.factor(test_data$Class)
# STEP 2: SCALING THE DATA (AFTER SPLIT)
# === Scale numeric variables in the training set ===
numeric_vars_train <- sapply(train_data, is.numeric)
train_data[numeric_vars_train] <- scale(train_data[numeric_vars_train])
# === Scale numeric variables in the test set using training set scaling parameters ===
# Ensure that only the same numeric columns are being scaled between train and test
numeric_vars_test <- sapply(test_data, is.numeric)
# Scale the test data, using the center and scale from train data
test_data[numeric_vars_test] <- scale(test_data[numeric_vars_test],
center = attr(train_data[, numeric_vars_train], "scaled:center"),
scale = attr(train_data[, numeric_vars_train], "scaled:scale"))
# STEP 3: TRAIN AND TEST DATASET
# === Train SVM model with RBF kernel ===
svm_model <- svm(Class ~ .,
data = train_data,
kernel = "radial",
cost = 1,
gamma = 0.01)
# === Predict on test set ===
predictions <- predict(svm_model, newdata = test_data)
# === Confusion Matrix ===
conf_matrix <- confusionMatrix(predictions, test_data$Class)
# Print confusion matrix
print(conf_matrix)
# Extract precision, recall, and F1-score
precision <- conf_matrix$byClass["Precision"]
recall <- conf_matrix$byClass["Recall"]
f1_score <- 2 * (precision * recall) / (precision + recall)
# Print performance metrics
print(paste("Precision: ", round(precision, 3)))
print(paste("Recall: ", round(recall, 3)))
print(paste("F1 Score: ", round(f1_score, 3_
# STEP 1: LOAD LIBRARIES
install.packages("e1071")
install.packages("caTools")
install.packages("caret")
install.packages("mlbench")
install.packages("ggplot2")
install.packages("pROC")
library(mlbench)
library(caret)
library(e1071)
library(caTools)
library(ggplot2)
library(pROC)
# STEP 2: LOAD, VIEW, AND PREPARE DATA SET
# Load the dataset
data("GermanCredit")
head(GermanCredit)
str(GermanCredit)
# Convert categorical variables to factors
GermanCredit[sapply(GermanCredit, is.character)] <- lapply(GermanCredit[sapply(GermanCredit, is.character)], factor)
# STEP 3: TRAIN AND TEST DATASET
# Split the dataset into training (70%) and test sets (30%)
set.seed(123)  # Set seed for reproducibility
split <- sample.split(GermanCredit$Class, SplitRatio = 0.7)
train_data <- subset(GermanCredit, split == TRUE)
test_data <- subset(GermanCredit, split == FALSE)
# SVM-STEP 1: REMOVE ZERO-VARIANCE FEATURES
# Identify and remove zero-variance predictors
nzv <- nearZeroVar(train_data)
if (length(nzv) > 0) {
train_data <- train_data[, -nzv]
test_data <- test_data[, -nzv]
}
# SVM-STEP 2: TRAIN SVM MODEL WITH RBF KERNEL
set.seed(123)  # Ensure reproducibility
svm_model <- svm(Class ~ .,
data = train_data,
kernel = "radial",  # Radial Basis Kernel
cost = 1,           # Regularization parameter
gamma = 0.01)       # Kernel parameter
# Print model details
print(svm_model)
# SVM-STEP 3: MAKE PREDICTIONS
predictions <- predict(svm_model, newdata = test_data)
# SVM-STEP 4: CONFUSION MATRIX + PERFORMANCE METRICS
conf_matrix <- confusionMatrix(predictions, test_data$Class)
# Print confusion matrix
print(conf_matrix)
# Extract precision, recall, and F1-score
precision <- conf_matrix$byClass["Precision"]
recall <- conf_matrix$byClass["Recall"]
f1_score <- 2 * (precision * recall) / (precision + recall)
# Print performance metrics
print(paste("Precision: ", round(precision, 3)))
print(paste("Recall: ", round(recall, 3)))
print(paste("F1 Score: ", round(f1_score, 3)))
# CONFUSION MATRIX VISUALIZATION
cm_table <- as.table(conf_matrix$table)
cm_df <- as.data.frame(cm_table)
colnames(cm_df) <- c("Actual", "Predicted", "Frequency")
# Create heatmap of the confusion matrix
ggplot(cm_df, aes(x = Actual, y = Predicted, fill = Frequency)) +
geom_tile(color = "white") +
geom_text(aes(label = Frequency), color = "black") +
scale_fill_gradient(low = "yellow", high = "darkgreen") +
labs(title = "Confusion Matrix Heatmap", x = "Actual", y = "Predicted") +
theme_minimal()
# SVM-STEP 5: ROC CURVE + AUC
# Get predicted probabilities for the positive class (assuming "Bad" is the positive class)
probabilities <- predict(svm_model, newdata = test_data, type = "prob")[, 2]
# SVM-STEP 1: REMOVE ZERO-VARIANCE FEATURES
# Identify and remove zero-variance predictors
nzv <- nearZeroVar(train_data)
if (length(nzv) > 0) {
train_data <- train_data[, -nzv]
test_data <- test_data[, -nzv]
}
# SVM-STEP 2: TRAIN SVM MODEL WITH RBF KERNEL
set.seed(123)  # Ensure reproducibility
svm_model <- svm(Class ~ .,
data = train_data,
kernel = "radial",  # Radial Basis Kernel
cost = 1,           # Regularization parameter
gamma = 0.01)       # Kernel parameter
# Print model details
print(svm_model)
# SVM-STEP 3: MAKE PREDICTIONS
predictions <- predict(svm_model, newdata = test_data)
# SVM-STEP 4: CONFUSION MATRIX + PERFORMANCE METRICS
conf_matrix <- confusionMatrix(predictions, test_data$Class)
# Print confusion matrix
print(conf_matrix)
# Extract precision, recall, and F1-score
precision <- conf_matrix$byClass["Precision"]
recall <- conf_matrix$byClass["Recall"]
f1_score <- 2 * (precision * recall) / (precision + recall)
# Print performance metrics
print(paste("Precision: ", round(precision, 3)))
print(paste("Recall: ", round(recall, 3)))
print(paste("F1 Score: ", round(f1_score, 3)))
style DC fill:#9f9,stroke:#333,stroke-width:2px
flowchart TD
required_packages <- c("tsf", "tidyverse", "lubridate")
install_if_missing <- required_packages[!(required_packages %in% installed.packages()[,"Package"])]
if (length(install_if_missing)) {
install.packages(install_if_missing)
}
library(tsf)
setwd("~/Desktop/PORTFOLIO/SQL-PROJECT/SQL_LSM_UK/DATASET")
london_smart_meters.tsf
